{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68022ab0-9484-443f-8b15-3ba3a55effbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import step, Output\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45e2479-ba95-4b1a-a1be-4b6160e8184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def pytorch_hpo_pipeline(\n",
    "    load_data,\n",
    "    run_hpo,\n",
    "    train_test,\n",
    "):\n",
    "    \"\"\"A `pipeline` to load data, load model, and train/evaluate the model.\"\"\"\n",
    "    train_dataloader, test_dataloader = load_data()\n",
    "    best_hparams = run_hpo(train_dataloader, test_dataloader)\n",
    "    train_test(best_hparams, train_dataloader, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9b9f80-4966-4df4-8376-f5e1cbf1bd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\"> /tmp/ipykernel_483427/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3067849278.py</span><span style=\"font-weight: bold\">:</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold\">31</span>                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"A `step` to load the Fashion MNIST dataset as a tuple of torch Datasets.\"\"\"</span>                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">▲</span>                                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndentationError: </span>expected an indented block\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m╭──────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m /tmp/ipykernel_483427/\u001b[0m\u001b[1;33m3067849278.py\u001b[0m\u001b[1m:\u001b[0m\u001b[1;94m31\u001b[0m                                                          \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[33m\"\"\"A `step` to load the Fashion MNIST dataset as a tuple of torch Datasets.\"\"\"\u001b[0m                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;91m▲\u001b[0m                                                                                                \u001b[91m│\u001b[0m\n",
       "\u001b[91m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mIndentationError: \u001b[0mexpected an indented block\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mnist():\n",
    "    \n",
    "    batch_size = 64\n",
    "\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "@step\n",
    "def load_data() -> Output(\n",
    "    train_dataloader=DataLoader, test_dataloader=DataLoader\n",
    "):\n",
    "    \"\"\"A `step` to load the Fashion MNIST dataset as a tuple of torch Datasets.\"\"\"\n",
    "\n",
    "    train_dataloader, test_dataloader = get_mnist()\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f3d353-e4b0-4e45-8690-3e7afa86aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hpo_model(trial):\n",
    "    CLASSES = 10\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "    in_features = 28 * 28\n",
    "    layers.append(nn.Flatten())\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f\"n_units_l{i}\", 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(f\"dropout_l{i}\", 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def objective(trial, train_dataloader, test_dataloader):\n",
    "\n",
    "    # Generate model\n",
    "    model = define_hpo_model(trial)\n",
    "    \n",
    "    # Train model\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    size = len(train_dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    size = len(test_dataloader.dataset)\n",
    "    num_batches = len(test_dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    test_accuracy = 100*correct\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "@step\n",
    "def run_hpo(\n",
    "    train_dataloader: DataLoader, \n",
    "    test_dataloader: DataLoader\n",
    ") -> dict:\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, train_dataloader, test_dataloader), n_trials=30, timeout=600)\n",
    "    \n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "    best = trial.params\n",
    "\n",
    "    print(\"Found best hyperparam dict from optimization work\")\n",
    "    print(best)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962e08bb-19a1-4333-8c7f-ae82c1da4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(hparam:dict):\n",
    "    CLASSES = 10\n",
    "    layers = []\n",
    "    in_features = 28 * 28\n",
    "    layers.append(nn.Flatten())\n",
    "    \n",
    "    print(hparam)\n",
    "    \n",
    "    for i in range(hparam['n_layers']):\n",
    "        out_features = hparam[f\"n_units_l{i}\"]\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = hparam[f\"dropout_l{i}\"]\n",
    "        layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4d56c1-b865-4871-8dcf-438bdbaab23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"A function to train a model for one epoch.\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    \"\"\"A function to test a model on the validation / test dataset.\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    test_accuracy = 100*correct\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089c46ef-775f-46a6-af7f-2f10ec9bc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def train_test(\n",
    "    best_hparams: dict,\n",
    "    train_dataloader: DataLoader, \n",
    "    test_dataloader: DataLoader\n",
    ") -> Output(trained_model=nn.Module, test_acc=float):\n",
    "    \"\"\"A `step` to train and evaluate a torch model on given dataloaders.\"\"\"\n",
    "    \n",
    "    epochs = 5\n",
    "    \n",
    "    model = define_model(best_hparams)\n",
    "    \n",
    "    print(\"Constructing optimized model:\")\n",
    "    print(model)\n",
    "\n",
    "    print(\"Using optimized hyperparams\")\n",
    "    print(best_hparams)\n",
    "\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    lr = best_hparams['lr']\n",
    "    optimizer_name = best_hparams['optimizer_name']\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    test_acc = 0\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_acc = test(test_dataloader, model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24973414-4318-4352-97bc-ac56fe181b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_483427/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2521008316.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_483427/2521008316.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'load_data'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_483427/\u001b[0m\u001b[1;33m2521008316.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_483427/2521008316.py'\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'load_data'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pytorch_hpo_pipeline(\n",
    "    load_data=load_data(),\n",
    "    run_hpo=run_hpo(),\n",
    "    train_test=train_test(),\n",
    ").run(unlisted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326d6d3-f432-48a8-aa0e-8127e2d9e746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf84e5-8767-47f3-969b-44fb89218241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0924c6-41b3-4200-b750-aaec9f02266b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbcb3d1-3acc-4e8e-ab46-c13770edae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('zenml-hpo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "28daa2db7ba61fb3b7fb1191c34e5dc56c2341f582f679c4c71e00b812b8bb12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
