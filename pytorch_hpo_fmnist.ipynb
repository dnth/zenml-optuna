{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68022ab0-9484-443f-8b15-3ba3a55effbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import step, Output\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45e2479-ba95-4b1a-a1be-4b6160e8184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def pytorch_hpo_pipeline(\n",
    "    load_data,\n",
    "    run_hpo,\n",
    "    train_test,\n",
    "):\n",
    "    \"\"\"A `pipeline` to load data, load model, and train/evaluate the model.\"\"\"\n",
    "    train_dataloader, test_dataloader = load_data()\n",
    "    best_hparams = run_hpo(train_dataloader, test_dataloader)\n",
    "    train_test(best_hparams, train_dataloader, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9b9f80-4966-4df4-8376-f5e1cbf1bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    \"\"\"A `step` to load the Fashion MNIST dataset as a tuple of torch Datasets.\"\"\"\n",
    "    batch_size = 64\n",
    "\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "@step\n",
    "def load_data() -> Output(\n",
    "    train_dataloader=DataLoader, test_dataloader=DataLoader\n",
    "):\n",
    "    train_dataloader, test_dataloader = get_mnist()\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f3d353-e4b0-4e45-8690-3e7afa86aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hpo_model(trial):\n",
    "    CLASSES = 10\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "    in_features = 28 * 28\n",
    "    layers.append(nn.Flatten())\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f\"n_units_l{i}\", 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(f\"dropout_l{i}\", 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def objective(trial, train_dataloader, test_dataloader):\n",
    "\n",
    "    # Generate model\n",
    "    model = define_hpo_model(trial)\n",
    "    \n",
    "    # Train model\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    size = len(train_dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    size = len(test_dataloader.dataset)\n",
    "    num_batches = len(test_dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    test_accuracy = 100*correct\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "@step\n",
    "def run_hpo(\n",
    "    train_dataloader: DataLoader, \n",
    "    test_dataloader: DataLoader\n",
    ") -> dict:\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, train_dataloader, test_dataloader), n_trials=30, timeout=600)\n",
    "    \n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "    best = trial.params\n",
    "    print(\"Found best hparam dict\")\n",
    "    print(best)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962e08bb-19a1-4333-8c7f-ae82c1da4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(hparam:dict):\n",
    "    CLASSES = 10\n",
    "    layers = []\n",
    "    in_features = 28 * 28\n",
    "    layers.append(nn.Flatten())\n",
    "    \n",
    "    print(hparam)\n",
    "    \n",
    "    for i in range(hparam['n_layers']):\n",
    "        out_features = hparam[f\"n_units_l{i}\"]\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = hparam[f\"dropout_l{i}\"]\n",
    "        layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4d56c1-b865-4871-8dcf-438bdbaab23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"A function to train a model for one epoch.\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    \"\"\"A function to test a model on the validation / test dataset.\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    test_accuracy = 100*correct\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089c46ef-775f-46a6-af7f-2f10ec9bc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def train_test(\n",
    "    best_hparams: dict,\n",
    "    train_dataloader: DataLoader, \n",
    "    test_dataloader: DataLoader\n",
    ") -> Output(trained_model=nn.Module, test_acc=float):\n",
    "    \"\"\"A `step` to train and evaluate a torch model on given dataloaders.\"\"\"\n",
    "    \n",
    "    epochs = 5\n",
    "    \n",
    "    model = define_model(best_hparams)\n",
    "    \n",
    "    print(\"Training optimized model:\")\n",
    "    print(model)\n",
    "\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    lr = best_hparams['lr']\n",
    "    optimizer_name = best_hparams['optimizer_name']\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    test_acc = 0\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_acc = test(test_dataloader, model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24973414-4318-4352-97bc-ac56fe181b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUnable to find ZenML repository in your current working directory (/home/dnth/Desktop/zenml-optuna) or any parent directories. If you want to use an existing repository which is in a different location, set the environment variable 'ZENML_REPOSITORY_PATH'. If you want to create a new repository, run \u001b[0m\u001b[33mzenml init\u001b[33m.\u001b[0m\n",
      "\u001b[1;35mRunning without an active repository root.\u001b[0m\n",
      "\u001b[1;35mRunning unlisted pipeline on stack \u001b[0m\u001b[33mdefault\u001b[1;35m (caching enabled)\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mload_data\u001b[1;35m has started.\u001b[0m\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70cc41ded0a4298bd208ee23e8679e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9856d3d983b9430589087817b3519520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd0226fa2894e2798a27d5ecb6574b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4583aeb6264041897de9997c34b9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mload_data\u001b[1;35m has finished in 21.214s.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mrun_hpo\u001b[1;35m has started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:17:59,109]\u001b[0m A new study created in memory with name: no-name-df324dac-2557-4144-aa15-b88bcb4b1076\u001b[0m\n",
      "\u001b[32m[I 2022-11-28 15:18:05,849]\u001b[0m Trial 0 finished with value: 26.200000000000003 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_l0': 0.3961601697991479, 'n_units_l1': 82, 'dropout_l1': 0.3035510660490758, 'optimizer_name': 'Adam', 'lr': 0.019021419954910607}. Best is trial 0 with value: 26.200000000000003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 1.768600 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:10,616]\u001b[0m Trial 1 finished with value: 75.08 and parameters: {'n_layers': 1, 'n_units_l0': 74, 'dropout_l0': 0.36826553637785686, 'optimizer_name': 'Adam', 'lr': 0.00010390044730062207}. Best is trial 1 with value: 75.08.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.728888 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:14,994]\u001b[0m Trial 2 finished with value: 60.8 and parameters: {'n_layers': 1, 'n_units_l0': 71, 'dropout_l0': 0.347159602323059, 'optimizer_name': 'SGD', 'lr': 0.0018918920206082803}. Best is trial 1 with value: 75.08.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 1.626096 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:19,867]\u001b[0m Trial 3 finished with value: 41.88 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_l0': 0.26815935032289706, 'n_units_l1': 116, 'dropout_l1': 0.41863132025606486, 'n_units_l2': 43, 'dropout_l2': 0.49916675447958436, 'optimizer_name': 'RMSprop', 'lr': 0.001626086763211247}. Best is trial 1 with value: 75.08.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 41.9%, Avg loss: 1.368762 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:24,293]\u001b[0m Trial 4 finished with value: 24.87 and parameters: {'n_layers': 2, 'n_units_l0': 88, 'dropout_l0': 0.34485062668012256, 'n_units_l1': 65, 'dropout_l1': 0.37613460964794454, 'optimizer_name': 'SGD', 'lr': 0.0007920479418469426}. Best is trial 1 with value: 75.08.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 24.9%, Avg loss: 2.265801 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:28,671]\u001b[0m Trial 5 finished with value: 82.59 and parameters: {'n_layers': 1, 'n_units_l0': 42, 'dropout_l0': 0.2903400160309909, 'optimizer_name': 'RMSprop', 'lr': 0.002654689681801413}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.479191 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:33,659]\u001b[0m Trial 6 finished with value: 67.36 and parameters: {'n_layers': 3, 'n_units_l0': 60, 'dropout_l0': 0.4571999254928992, 'n_units_l1': 86, 'dropout_l1': 0.3457918763958716, 'n_units_l2': 14, 'dropout_l2': 0.2834799937822633, 'optimizer_name': 'Adam', 'lr': 0.014222548381593557}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.900442 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:38,674]\u001b[0m Trial 7 finished with value: 26.07 and parameters: {'n_layers': 2, 'n_units_l0': 59, 'dropout_l0': 0.3461377791047407, 'n_units_l1': 86, 'dropout_l1': 0.2374503532201533, 'optimizer_name': 'SGD', 'lr': 0.000837764650650975}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 26.1%, Avg loss: 2.234208 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:42,962]\u001b[0m Trial 8 finished with value: 6.49 and parameters: {'n_layers': 2, 'n_units_l0': 63, 'dropout_l0': 0.4327630048816772, 'n_units_l1': 30, 'dropout_l1': 0.20451898829192297, 'optimizer_name': 'SGD', 'lr': 1.39321814723787e-05}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 6.5%, Avg loss: 2.310410 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:47,389]\u001b[0m Trial 9 finished with value: 69.39 and parameters: {'n_layers': 2, 'n_units_l0': 120, 'dropout_l0': 0.28312308345066056, 'n_units_l1': 49, 'dropout_l1': 0.4105980650589946, 'optimizer_name': 'SGD', 'lr': 0.020613039336336233}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.766851 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:51,690]\u001b[0m Trial 10 finished with value: 75.84 and parameters: {'n_layers': 1, 'n_units_l0': 38, 'dropout_l0': 0.2088113357158836, 'optimizer_name': 'RMSprop', 'lr': 0.0001369201393087794}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.703749 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:18:55,947]\u001b[0m Trial 11 finished with value: 71.72 and parameters: {'n_layers': 1, 'n_units_l0': 37, 'dropout_l0': 0.20214569077929342, 'optimizer_name': 'RMSprop', 'lr': 9.099161798301082e-05}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.791519 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:00,330]\u001b[0m Trial 12 finished with value: 75.48 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_l0': 0.20681887059754236, 'optimizer_name': 'RMSprop', 'lr': 0.0001503753718716785}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.700117 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:04,887]\u001b[0m Trial 13 finished with value: 10.100000000000001 and parameters: {'n_layers': 1, 'n_units_l0': 34, 'dropout_l0': 0.2651358800347818, 'optimizer_name': 'RMSprop', 'lr': 0.08751351672194238}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 10.1%, Avg loss: 2.307105 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:09,566]\u001b[0m Trial 14 finished with value: 51.71 and parameters: {'n_layers': 1, 'n_units_l0': 44, 'dropout_l0': 0.29387175020678136, 'optimizer_name': 'RMSprop', 'lr': 1.0019391469664987e-05}. Best is trial 5 with value: 82.59.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 1.773739 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:14,215]\u001b[0m Trial 15 finished with value: 82.91 and parameters: {'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.227952943193382, 'optimizer_name': 'RMSprop', 'lr': 0.004079093928767621}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.460972 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:19,001]\u001b[0m Trial 16 finished with value: 82.67 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.24061471681651747, 'optimizer_name': 'RMSprop', 'lr': 0.004847977927040362}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.489378 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:24,018]\u001b[0m Trial 17 finished with value: 35.65 and parameters: {'n_layers': 3, 'n_units_l0': 113, 'dropout_l0': 0.2417402966314778, 'n_units_l1': 5, 'dropout_l1': 0.4889414127177789, 'n_units_l2': 128, 'dropout_l2': 0.2091755833983707, 'optimizer_name': 'RMSprop', 'lr': 0.00570967468744407}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 1.474371 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:28,661]\u001b[0m Trial 18 finished with value: 25.480000000000004 and parameters: {'n_layers': 1, 'n_units_l0': 98, 'dropout_l0': 0.24388482039276696, 'optimizer_name': 'RMSprop', 'lr': 0.07837101634337358}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 25.5%, Avg loss: 1.906742 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:33,564]\u001b[0m Trial 19 finished with value: 71.17 and parameters: {'n_layers': 2, 'n_units_l0': 104, 'dropout_l0': 0.24857175790153668, 'n_units_l1': 122, 'dropout_l1': 0.4893164852314044, 'optimizer_name': 'RMSprop', 'lr': 0.006522000083956164}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.919177 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:38,271]\u001b[0m Trial 20 finished with value: 82.31 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.30752102026984907, 'optimizer_name': 'Adam', 'lr': 0.0003849796069931933}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.503292 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:42,745]\u001b[0m Trial 21 finished with value: 82.74000000000001 and parameters: {'n_layers': 1, 'n_units_l0': 89, 'dropout_l0': 0.2994710525274578, 'optimizer_name': 'RMSprop', 'lr': 0.004749284214492657}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.473017 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:47,349]\u001b[0m Trial 22 finished with value: 79.46 and parameters: {'n_layers': 1, 'n_units_l0': 88, 'dropout_l0': 0.3206119353692389, 'optimizer_name': 'RMSprop', 'lr': 0.005711688947205896}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.516663 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:52,001]\u001b[0m Trial 23 finished with value: 81.67999999999999 and parameters: {'n_layers': 1, 'n_units_l0': 86, 'dropout_l0': 0.22536349584921261, 'optimizer_name': 'RMSprop', 'lr': 0.0033627163836343994}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.483227 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:19:56,663]\u001b[0m Trial 24 finished with value: 81.66 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.25244944016443394, 'optimizer_name': 'RMSprop', 'lr': 0.009054660012823212}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.491318 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:20:01,524]\u001b[0m Trial 25 finished with value: 10.0 and parameters: {'n_layers': 2, 'n_units_l0': 80, 'dropout_l0': 0.23012950420907588, 'n_units_l1': 8, 'dropout_l1': 0.2687997299398122, 'optimizer_name': 'RMSprop', 'lr': 0.03776395997768375}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.305852 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:20:06,249]\u001b[0m Trial 26 finished with value: 81.67999999999999 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.4911411140953038, 'optimizer_name': 'RMSprop', 'lr': 0.00040309169758078004}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.528528 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:20:10,906]\u001b[0m Trial 27 finished with value: 82.44 and parameters: {'n_layers': 1, 'n_units_l0': 118, 'dropout_l0': 0.31029329505520586, 'optimizer_name': 'RMSprop', 'lr': 0.0033680340438012176}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.474469 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:20:15,627]\u001b[0m Trial 28 finished with value: 35.449999999999996 and parameters: {'n_layers': 2, 'n_units_l0': 108, 'dropout_l0': 0.2696647060182065, 'n_units_l1': 35, 'dropout_l1': 0.3125263569372484, 'optimizer_name': 'RMSprop', 'lr': 0.03442046512320943}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 1.686688 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-28 15:20:20,477]\u001b[0m Trial 29 finished with value: 73.3 and parameters: {'n_layers': 2, 'n_units_l0': 91, 'dropout_l0': 0.40794996837653785, 'n_units_l1': 104, 'dropout_l1': 0.43539262406314616, 'optimizer_name': 'Adam', 'lr': 0.01316552053542253}. Best is trial 15 with value: 82.91.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.705535 \n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  30\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  30\n",
      "Best trial:\n",
      "  Value:  82.91\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 96\n",
      "    dropout_l0: 0.227952943193382\n",
      "    optimizer_name: RMSprop\n",
      "    lr: 0.004079093928767621\n",
      "Found best hparam dict\n",
      "{'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.227952943193382, 'optimizer_name': 'RMSprop', 'lr': 0.004079093928767621}\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mrun_hpo\u001b[1;35m has finished in 2m21s.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mtrain_test\u001b[1;35m has started.\u001b[0m\n",
      "{'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.227952943193382, 'optimizer_name': 'RMSprop', 'lr': 0.004079093928767621}\n",
      "Training optimized model:\n",
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=96, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.227952943193382, inplace=False)\n",
      "  (4): Linear(in_features=96, out_features=10, bias=True)\n",
      "  (5): LogSoftmax(dim=1)\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.312642  [    0/60000]\n",
      "loss: 0.810983  [ 6400/60000]\n",
      "loss: 0.485056  [12800/60000]\n",
      "loss: 0.610181  [19200/60000]\n",
      "loss: 0.581463  [25600/60000]\n",
      "loss: 0.512054  [32000/60000]\n",
      "loss: 0.499475  [38400/60000]\n",
      "loss: 0.709568  [44800/60000]\n",
      "loss: 0.578566  [51200/60000]\n",
      "loss: 0.514251  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.467549 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.359939  [    0/60000]\n",
      "loss: 0.439503  [ 6400/60000]\n",
      "loss: 0.401997  [12800/60000]\n",
      "loss: 0.538125  [19200/60000]\n",
      "loss: 0.400590  [25600/60000]\n",
      "loss: 0.484595  [32000/60000]\n",
      "loss: 0.508585  [38400/60000]\n",
      "loss: 0.623614  [44800/60000]\n",
      "loss: 0.551413  [51200/60000]\n",
      "loss: 0.425435  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.436604 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.371325  [    0/60000]\n",
      "loss: 0.517317  [ 6400/60000]\n",
      "loss: 0.289084  [12800/60000]\n",
      "loss: 0.362051  [19200/60000]\n",
      "loss: 0.416775  [25600/60000]\n",
      "loss: 0.484625  [32000/60000]\n",
      "loss: 0.382983  [38400/60000]\n",
      "loss: 0.519426  [44800/60000]\n",
      "loss: 0.562482  [51200/60000]\n",
      "loss: 0.477927  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.421478 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.330518  [    0/60000]\n",
      "loss: 0.421065  [ 6400/60000]\n",
      "loss: 0.270585  [12800/60000]\n",
      "loss: 0.380389  [19200/60000]\n",
      "loss: 0.477705  [25600/60000]\n",
      "loss: 0.404579  [32000/60000]\n",
      "loss: 0.339187  [38400/60000]\n",
      "loss: 0.510549  [44800/60000]\n",
      "loss: 0.461537  [51200/60000]\n",
      "loss: 0.475477  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.446209 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.375395  [    0/60000]\n",
      "loss: 0.421616  [ 6400/60000]\n",
      "loss: 0.281308  [12800/60000]\n",
      "loss: 0.410625  [19200/60000]\n",
      "loss: 0.356781  [25600/60000]\n",
      "loss: 0.449317  [32000/60000]\n",
      "loss: 0.356665  [38400/60000]\n",
      "loss: 0.541750  [44800/60000]\n",
      "loss: 0.518226  [51200/60000]\n",
      "loss: 0.408234  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.415492 \n",
      "\n",
      "Done!\n",
      "\u001b[1;35mStep \u001b[0m\u001b[33mtrain_test\u001b[1;35m has finished in 23.592s.\u001b[0m\n",
      "\u001b[1;35mPipeline run \u001b[0m\u001b[33mpytorch_hpo_pipeline-2022_11_28-15_17_37_675914\u001b[1;35m has finished in 3m6s.\u001b[0m\n",
      "\u001b[1;35mPipeline visualization can be seen in the ZenML Dashboard. Run \u001b[0m\u001b[33mzenml up\u001b[1;35m to see your pipeline!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pytorch_hpo_pipeline(\n",
    "    load_data=load_data(),\n",
    "    run_hpo=run_hpo(),\n",
    "    train_test=train_test(),\n",
    ").run(unlisted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326d6d3-f432-48a8-aa0e-8127e2d9e746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf84e5-8767-47f3-969b-44fb89218241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0924c6-41b3-4200-b750-aaec9f02266b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbcb3d1-3acc-4e8e-ab46-c13770edae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('zenml-hpo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "28daa2db7ba61fb3b7fb1191c34e5dc56c2341f582f679c4c71e00b812b8bb12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
